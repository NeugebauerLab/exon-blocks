{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e94c8ce-9ba8-4124-ba4d-3677d4b76bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### what it does: Detremines exon block coordinates and surrounding exon coordinates \n",
    "### Input: gtf file and and csv with block exon coords (output from script 3) \n",
    "##output: exon-block coordinates csv and csv with upstream and downstream of block exon coordinates (ups/dns)\n",
    "## Date: 4/28/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a829fee-4aff-4755-9d27-e4b64a0ce19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "223bb09e-c72b-4249-9222-a08fa56a33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('block_exons_ddPSImax0.2_adjacent.csv')\n",
    "gtf_file = 'gencode.v44.basic.annotation.gtf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a691c81d-b834-469a-958c-795f787ac0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/012b_sqx2bl9vk20cyklfj_r0000gn/T/ipykernel_75084/456965489.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  coords_to_keep = grouped.apply(find_coords_with_small_deltapsi_diff).explode().unique()\n",
      "/var/folders/s5/012b_sqx2bl9vk20cyklfj_r0000gn/T/ipykernel_75084/456965489.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped = bl_ex.groupby('gene_name').apply(lambda x: x.sort_values('exon_number')).reset_index(drop=True)\n",
      "/var/folders/s5/012b_sqx2bl9vk20cyklfj_r0000gn/T/ipykernel_75084/456965489.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  all_subgroups = grouped.apply(create_subgroups)\n"
     ]
    }
   ],
   "source": [
    "# ---- STEP 1: FIND COORDINATED EXONS ----\n",
    "# Group by gene_name\n",
    "grouped = df.groupby('gene_name')\n",
    "\n",
    "# Function to find exons with small dPSI differences (<= 0.02)\n",
    "def find_coords_with_small_deltapsi_diff(group):\n",
    "    result = []\n",
    "    for i in range(len(group)):\n",
    "        for j in range(i + 1, len(group)):\n",
    "            if abs(group.iloc[i]['dPSI'] - group.iloc[j]['dPSI']) <= 0.02:\n",
    "                result.append(group.iloc[i]['Coord'])\n",
    "                result.append(group.iloc[j]['Coord'])\n",
    "    return result\n",
    "\n",
    "# Apply function to identify relevant exon coordinates\n",
    "coords_to_keep = grouped.apply(find_coords_with_small_deltapsi_diff).explode().unique()\n",
    "\n",
    "# Filter dataset to retain only relevant exons\n",
    "bl_ex = df[df['Coord'].isin(coords_to_keep)]\n",
    "\n",
    "# ---- STEP 2: IDENTIFY ADJACENT EXONS ----\n",
    "# Group by gene and sort by exon_number\n",
    "grouped = bl_ex.groupby('gene_name').apply(lambda x: x.sort_values('exon_number')).reset_index(drop=True)\n",
    "\n",
    "# Identify neighbors (previous and next exon with difference of 1)\n",
    "grouped['next_exon_diff'] = grouped.groupby('gene_name')['exon_number'].shift(-1) - grouped['exon_number']\n",
    "grouped['prev_exon_diff'] = grouped['exon_number'] - grouped.groupby('gene_name')['exon_number'].shift(1)\n",
    "\n",
    "# Mark exons that have direct neighbors\n",
    "grouped['has_neighbor'] = ((grouped['next_exon_diff'] == 1) | (grouped['prev_exon_diff'] == 1)).astype(int)\n",
    "\n",
    "# Keep only exons with adjacent neighbors\n",
    "bl_ex_ad = grouped[grouped['has_neighbor'] == 1].reset_index(drop=True)\n",
    "\n",
    "# ---- STEP 3: GROUP INTO BLOCKS BASED ON dPSI PROXIMITY ----\n",
    "proximity_threshold = 0.02\n",
    "\n",
    "# Function to create subgroups based on dPSI proximity within each gene_name group\n",
    "def create_subgroups(group):\n",
    "    group = group.sort_values(by='dPSI').reset_index(drop=True)\n",
    "    subgroups = []\n",
    "    current_group = [group.iloc[0]]\n",
    "    for i in range(1, len(group)):\n",
    "        if abs(group.iloc[i]['dPSI'] - group.iloc[i-1]['dPSI']) <= proximity_threshold:\n",
    "            current_group.append(group.iloc[i])\n",
    "        else:\n",
    "            subgroups.append(current_group)\n",
    "            current_group = [group.iloc[i]]\n",
    "    subgroups.append(current_group)\n",
    "    return subgroups\n",
    "\n",
    "# Apply subgrouping function\n",
    "grouped = bl_ex_ad.groupby('gene_name')\n",
    "all_subgroups = grouped.apply(create_subgroups)\n",
    "\n",
    "# ---- STEP 4: IDENTIFY BLOCKS ----\n",
    "# Function to parse Coord and return chromosome, start, end\n",
    "def parse_coord(coord):\n",
    "    chrom, positions = coord.split(':')\n",
    "    start, end = map(int, positions.split('-'))\n",
    "    return chrom, start, end\n",
    "\n",
    "# Function to check if exons within the same block are adjacent\n",
    "def are_exons_adjacent(block):\n",
    "    exon_numbers = sorted(block['exon_number'])\n",
    "    return all(exon_numbers[i] + 1 == exon_numbers[i + 1] for i in range(len(exon_numbers) - 1))\n",
    "\n",
    "# Function to calculate block start and end\n",
    "def calculate_block_start_end(block):\n",
    "    chrom = block.iloc[0]['Coord'].split(':')[0]\n",
    "    strand = block.iloc[0]['Strand']\n",
    "    start_positions = [parse_coord(entry['Coord'])[1] for _, entry in block.iterrows()]\n",
    "    end_positions = [parse_coord(entry['Coord'])[2] for _, entry in block.iterrows()]\n",
    "    \n",
    "    block_start = min(start_positions)\n",
    "    block_end = max(end_positions)\n",
    "    \n",
    "    # Ensure block_start is always smaller than block_end for BED file format\n",
    "    if block_start > block_end:\n",
    "        block_start, block_end = block_end, block_start\n",
    "    \n",
    "    return chrom, block_start, block_end, strand\n",
    "\n",
    "# Create a new DataFrame to store block information\n",
    "blocks_data = []\n",
    "\n",
    "for gene_name, gene_subgroups in all_subgroups.items():\n",
    "    for block in gene_subgroups:\n",
    "        block_df = pd.DataFrame(block)  # Convert block to DataFrame\n",
    "        \n",
    "        if not are_exons_adjacent(block_df):\n",
    "            continue  # Skip blocks where exons are not adjacent\n",
    "        \n",
    "        chrom, block_start, block_end, strand = calculate_block_start_end(block_df)\n",
    "        number_of_exons = len(block_df)\n",
    "        block_coord = f\"{chrom}:{block_start}-{block_end}\"\n",
    "        \n",
    "        blocks_data.append({\n",
    "            'chr': chrom,\n",
    "            'gene_name': gene_name,\n",
    "            'block_start': block_start,\n",
    "            'block_end': block_end,\n",
    "            'strand': strand,\n",
    "            'number_of_exons': number_of_exons,\n",
    "            'block_coord': block_coord\n",
    "        })\n",
    "\n",
    "# Create final DataFrame\n",
    "blocks_df = pd.DataFrame(blocks_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd3f501-7b7a-43a9-99f6-3ca3bbf78d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_df.to_csv('exon_block_coordinates.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b218bd9-768f-464a-8351-01a156caabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- GET SURROUNDING EXON COORDINATES ----\n",
    "\n",
    "# ---- STEP 1: PARSE GTF FILE ----\n",
    "# Function to parse the GTF file and extract relevant exon information\n",
    "def parse_gtf(gtf_file):\n",
    "    # Read GTF file\n",
    "    gtf_df = pd.read_csv(gtf_file, sep='\\t', comment='#', header=None, names=[\n",
    "        'seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'])\n",
    "    \n",
    "    # Filter for exon entries only\n",
    "    gtf_df = gtf_df[gtf_df['feature'] == 'exon']\n",
    "    \n",
    "    # Extract gene_name, exon_number, and transcript_support_level (tsl)\n",
    "    gtf_df['exon_number'] = gtf_df['attribute'].str.extract(r'exon_number\\s+\"?(\\d+)\"?')\n",
    "    gtf_df['tsl'] = gtf_df['attribute'].str.extract(r'transcript_support_level\\s+\"?(\\d+)\"?')\n",
    "    gtf_df['gene_name'] = gtf_df['attribute'].str.extract(r'gene_name\\s+\"([^\"]+)\"')\n",
    "    \n",
    "    # Convert to appropriate types\n",
    "    gtf_df['exon_number'] = pd.to_numeric(gtf_df['exon_number'], errors='coerce').fillna(-1).astype(int)\n",
    "    gtf_df['tsl'] = pd.to_numeric(gtf_df['tsl'], errors='coerce').fillna(-1).astype(int)\n",
    "    gtf_df['start'] = gtf_df['start'].astype(int)\n",
    "    gtf_df['end'] = gtf_df['end'].astype(int)\n",
    "    \n",
    "    return gtf_df[['seqname', 'gene_name', 'exon_number', 'tsl', 'start', 'end', 'strand']]\n",
    "\n",
    "\n",
    "# ---- STEP 2: IDENTIFY UPSTREAM & DOWNSTREAM EXONS ----\n",
    "\n",
    "# Function to find upstream and downstream exon coordinates\n",
    "def find_upstream_downstream(gtf_data, blocks_data):\n",
    "    results = []\n",
    "    \n",
    "    for _, row in blocks_data.iterrows():\n",
    "        chrom = row['chr']\n",
    "        gene = row['gene_name']\n",
    "        block_start = row['block_start']\n",
    "        block_end = row['block_end']\n",
    "        \n",
    "        # Filter GTF data for matching gene and chromosome\n",
    "        gene_exons = gtf_data[(gtf_data['gene_name'] == gene) & (gtf_data['seqname'] == chrom)]\n",
    "        \n",
    "        # Prefer transcripts with tsl == 1\n",
    "        preferred_exons = gene_exons[gene_exons['tsl'] == 1]\n",
    "        if preferred_exons.empty:\n",
    "            preferred_exons = gene_exons  # Fall back to all if no tsl == 1\n",
    "        \n",
    "        # Find upstream exon (closest exon before block_start)\n",
    "        upstream_exon = preferred_exons[preferred_exons['end'] < block_start].sort_values(by='end', ascending=False).head(1)\n",
    "        start_ups_exon = int(upstream_exon['start'].values[0]) if not upstream_exon.empty else None\n",
    "        end_ups_exon = int(upstream_exon['end'].values[0]) if not upstream_exon.empty else None\n",
    "\n",
    "        # Find downstream exon (closest exon after block_end)\n",
    "        downstream_exon = preferred_exons[preferred_exons['start'] > block_end].sort_values(by='start', ascending=True).head(1)\n",
    "        start_dns_exon = int(downstream_exon['start'].values[0]) if not downstream_exon.empty else None\n",
    "        end_dns_exon = int(downstream_exon['end'].values[0]) if not downstream_exon.empty else None\n",
    "\n",
    "        results.append({\n",
    "            'chr': chrom,\n",
    "            'gene_name': gene,\n",
    "            'block_start': block_start,\n",
    "            'block_end': block_end,\n",
    "            'strand': row['strand'],\n",
    "            'number_of_exons': row['number_of_exons'],\n",
    "            'block_coord': row['block_coord'],\n",
    "            'start_ups_exon': start_ups_exon,\n",
    "            'end_ups_exon': end_ups_exon,\n",
    "            'start_dns_exon': start_dns_exon,\n",
    "            'end_dns_exon': end_dns_exon\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734ff280-5d99-4428-b889-c1b380e5c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- RUN FUNCTIONS ----\n",
    "\n",
    "# Parse the GTF file\n",
    "gtf_df = parse_gtf(gtf_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b0cd88d-b08d-4beb-aa3c-fb051bd1cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to find upstream and downstream exon coordinates\n",
    "final_blocks_df = find_upstream_downstream(gtf_df, blocks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e79f0648-2e32-4f3b-bb25-ebdfab871e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where any NaN value exists\n",
    "final_blocks_df = final_blocks_df.dropna()\n",
    "\n",
    "final_blocks_df[['start_ups_exon', 'end_ups_exon', 'start_dns_exon', 'end_dns_exon']] = (\n",
    "    final_blocks_df[['start_ups_exon', 'end_ups_exon', 'start_dns_exon', 'end_dns_exon']]\n",
    "    .astype(int)  # Convert to integer type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5dc1f76-d7ae-418e-bd5f-d726476e3bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_blocks_df.to_csv('exon_block_coordinates_ups_dns.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e024ca-4cd7-46c0-bac0-098789b643c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
