{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62512cde-6401-475b-8a15-f98fab6dff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### purpose: get 5' and 3' splice sites for all exons in whippet analysis (related to Figure 6)\n",
    "### Input: output from script 1 (whippet_CE_gene_name_exon_number.csv)\n",
    "#          and genome.fa used for mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde2f93e-4487-40b2-b50d-ccda44634204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import pybedtools\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from splicing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93b25dfe-7ece-47f7-bb10-0bb853f1e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read input.csv\n",
    "wh = pd.read_csv(\"whippet_CE_gene_name_exon_number.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a108ee-2e93-4461-9a9d-e2dab8a4ccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    chr     start       end                    name  score strand\n",
      "0  chr1  44740913  44741007  chr1:44740913-44741007      0      +\n",
      "1  chr1  44747384  44747485  chr1:44747384-44747485      0      +\n",
      "2  chr1  44747652  44747700  chr1:44747652-44747700      0      +\n",
      "3  chr1  44750442  44750564  chr1:44750442-44750564      0      +\n",
      "4  chr1  44753132  44753254  chr1:44753132-44753254      0      +\n"
     ]
    }
   ],
   "source": [
    "# Extract chromosome, start, and end\n",
    "coord_split = wh['Coord'].str.extract(r'(?P<chr>chr[\\dXYM]+):(?P<start>\\d+)-(?P<end>\\d+)')\n",
    "\n",
    "# Convert extracted columns to integers\n",
    "wh_bed = pd.DataFrame()\n",
    "wh_bed[\"chr\"] = coord_split[\"chr\"]\n",
    "wh_bed[\"start\"] = coord_split[\"start\"].astype(int)\n",
    "wh_bed[\"end\"] = coord_split[\"end\"].astype(int)\n",
    "wh_bed[\"name\"] = wh[\"Coord\"].loc[coord_split.index]  # Align index\n",
    "wh_bed[\"score\"] = 0\n",
    "wh_bed[\"strand\"] = wh[\"Strand\"].loc[coord_split.index]  # Align index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74107701-331f-4a1c-8284-ec959fb0eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = \"GRCh38.p14.genome.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da7695e7-889f-4e9a-a467-ad631b56bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get splice site sequences\n",
    "\n",
    "#Initiate placeholders\n",
    "wh_bed[\"5_start\"] = 0\n",
    "wh_bed[\"5_end\"] = 0\n",
    "wh_bed[\"3_start\"] = 0\n",
    "wh_bed[\"3_end\"] = 0\n",
    "\n",
    "for idx, i in wh_bed.iterrows():\n",
    "    if i.strand == \"+\":\n",
    "        wh_bed[\"5_start\"][idx] = i.end - 3\n",
    "        wh_bed[\"5_end\"][idx] = i.end + 6\n",
    "        wh_bed[\"3_start\"][idx] = i.start - 21\n",
    "        wh_bed[\"3_end\"][idx] = i.start + 2\n",
    "    else:\n",
    "        wh_bed[\"5_start\"][idx] = i.start - 7\n",
    "        wh_bed[\"5_end\"][idx] = i.start + 2\n",
    "        wh_bed[\"3_start\"][idx] = i.end - 3\n",
    "        wh_bed[\"3_end\"][idx] = i.end + 20\n",
    "        \n",
    "wh_5 = wh_bed[[\"chr\", \"5_start\", \"5_end\", \"name\", \"score\", \"strand\"]]\n",
    "wh_3 = wh_bed[[\"chr\", \"3_start\", \"3_end\", \"name\", \"score\", \"strand\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dedaee4-e0e4-4f44-8a12-b5d00f6607ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_seqs_5 = get_sequence_from_bed(wh_5, genome)\n",
    "wh_seqs_3 = get_sequence_from_bed(wh_3, genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8363f0b3-bf8f-44a4-b53b-e9b3a047dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_5['5ss_seq']=wh_seqs_5\n",
    "wh_3['3ss_seq']=wh_seqs_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a6d916b-547e-4b3b-8526-671edf7c9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write sequences into fasta files, keeping the exon coordinate as name\n",
    "\n",
    "with open(\"5ss_whippet.fasta\", \"w\") as f:\n",
    "    for idx, line in enumerate(wh_seqs_5):\n",
    "        if idx < len(wh_5.name):  # Ensure index is within bounds\n",
    "            f.write(\">\" + wh_5.name.iloc[idx] + \"\\n\" + line + \"\\n\")\n",
    "\n",
    "with open(\"3ss_whippet.fasta\", \"w\") as f:\n",
    "    for idx, line in enumerate(wh_seqs_3):\n",
    "        if idx < len(wh_3.name):  # Ensure index is within bounds\n",
    "            f.write(\">\" + wh_3.name.iloc[idx] + \"\\n\" + line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bef1a41d-d606-4987-8f68-0678a3115b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Coord  MaxEnt\n",
      "0  chr1:44740913-44741007\\    9.65\n",
      "1  chr1:44747384-44747485\\   10.28\n",
      "2  chr1:44747652-44747700\\    9.72\n",
      "3  chr1:44750442-44750564\\    8.41\n",
      "4  chr1:44753132-44753254\\    6.89\n",
      "                     Coord  MaxEnt\n",
      "0  chr1:44740913-44741007\\    8.89\n",
      "1  chr1:44747384-44747485\\   10.53\n",
      "2  chr1:44747652-44747700\\    8.00\n",
      "3  chr1:44750442-44750564\\    9.20\n",
      "4  chr1:44753132-44753254\\   11.19\n"
     ]
    }
   ],
   "source": [
    "#In the next step you need to get MaxEnt scores (http://hollywood.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq_acc.html),\n",
    "# uploading the generated fasta files and setting to Maximum Entropy model score. Save the output in a txt file and change name to \".fa\".\n",
    "\n",
    "\n",
    "# Dictionary to store the coordinates and MaxEnt scores 5ss\n",
    "coord_maxent_dict_wh_5 = {}\n",
    "\n",
    "with open(\"5ss.whippet.maxent.fa\", \"r\") as f:\n",
    "    current_coord = None\n",
    "    for line in f:\n",
    "        if line.startswith(\">\"):  # Header line\n",
    "            current_coord = line.strip().lstrip(\">\")\n",
    "        else:  # Sequence line with MaxEnt score\n",
    "            match = re.search(r\"MAXENT:\\s*([-+]?\\d*\\.\\d+|\\d+)\", line)\n",
    "            if match:\n",
    "                max_ent_5 = float(match.group(1))\n",
    "                if current_coord:\n",
    "                    coord_maxent_dict_wh_5[current_coord] = max_ent_5\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "maxent_wh_5 = pd.DataFrame(list(coord_maxent_dict_wh_5.items()), columns=['Coord', 'MaxEnt'])\n",
    "\n",
    "# Print to verify\n",
    "print(maxent_wh_5.head())\n",
    "\n",
    "# Dictionary to store the coordinates and MaxEnt scores 3ss\n",
    "coord_maxent_dict_wh_3 = {}\n",
    "\n",
    "with open(\"3ss.whippet.maxent.fa\", \"r\") as f:\n",
    "    current_coord = None\n",
    "    for line in f:\n",
    "        if line.startswith(\">\"):  # Header line\n",
    "            current_coord = line.strip().lstrip(\">\")\n",
    "        else:  # Sequence line with MaxEnt score\n",
    "            match = re.search(r\"MAXENT:\\s*([-+]?\\d*\\.\\d+|\\d+)\", line)\n",
    "            if match:\n",
    "                max_ent_3 = float(match.group(1))\n",
    "                if current_coord:\n",
    "                    coord_maxent_dict_wh_3[current_coord] = max_ent_3\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "maxent_wh_3 = pd.DataFrame(list(coord_maxent_dict_wh_3.items()), columns=['Coord', 'MaxEnt'])\n",
    "\n",
    "# # Print to verify\n",
    "# print(maxent_wh_3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c58ba36e-e27c-4421-b110-bea273413943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any trailing backslashes from 'Coord' in maxent_df\n",
    "maxent_wh_5['Coord'] = maxent_wh_5['Coord'].str.strip().str.rstrip('\\\\')\n",
    "maxent_wh_3['Coord'] = maxent_wh_3['Coord'].str.strip().str.rstrip('\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ce3972e-d669-4f48-9008-e621ff82a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on 'name' in wh_5 which is equivalent to 'Coord' in maxent_wh_5\n",
    "wh_5_me = wh_5.merge(maxent_wh_5, left_on='name', right_on='Coord', how='left')\n",
    "wh_3_me = wh_3.merge(maxent_wh_3, left_on='name', right_on='Coord', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f68efcbf-21ec-4238-a9c6-72db5c9e1674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final wh length: 121888\n"
     ]
    }
   ],
   "source": [
    "# Rename columns in wh_5_me\n",
    "wh_5_me_renamed = wh_5_me.rename(columns={'MaxEnt': 'MaxEnt_5ss'})\n",
    "\n",
    "# Rename columns in wh_3_me\n",
    "wh_3_me_renamed = wh_3_me.rename(columns={'MaxEnt': 'MaxEnt_3ss'})\n",
    "\n",
    "# Deduplicate `wh_5_me` and `wh_3_me` to ensure one-to-one mapping\n",
    "wh_5_me_unique = wh_5_me.rename(columns={'MaxEnt': 'MaxEnt_5ss'}).drop_duplicates(subset=\"Coord\")\n",
    "wh_3_me_unique = wh_3_me.rename(columns={'MaxEnt': 'MaxEnt_3ss'}).drop_duplicates(subset=\"Coord\")\n",
    "\n",
    "# Merge wh with wh_5_me and wh_3_me\n",
    "wh = wh.merge(wh_5_me_unique[['Coord', '5ss_seq', 'MaxEnt_5ss']], on='Coord', how='left')\n",
    "wh = wh.merge(wh_3_me_unique[['Coord', '3ss_seq', 'MaxEnt_3ss']], on='Coord', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "425a70ed-1e85-4f4f-a2ba-18c46b73d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh.to_csv(\"whippet_CE_gene_name_exon_number_maxent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3991bf6-1ebc-4c3a-a3d2-764340ffe213",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_block_skip = pd.read_csv()\n",
    "middle_block_skip = pd.read_csv()\n",
    "last_block_skip = pd.read_csv()\n",
    "\n",
    "first_block_incl = pd.read_csv()\n",
    "middle_block_incl = pd.read_csv()\n",
    "last_block_incl = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71834e-b69e-4b1a-89ab-2bdb5d9fe189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
